# 相机视频播放器

## 简介

&emsp;比较简单的小项目, 涉及到的第三方框架如下:

1. vue: 基本的前端框架
2. [element-ui](https://element.eleme.cn/2.5/#/zh-CN): ui 框架
3. [mpegts.js](https://github.com/xqq/mpegts.js): 视频流播放框架

&emsp;实现的主要功能如下:

* 根据接口获取相机 id 信息
* 根据相机 id 信息通过接口播放相机画面, 并且能够根据后台接口操作相机(上下左右旋转、调节焦距)
* 在画面上绘制图形, 并且通过后台接口, 在播放相机的画面上显示, 并且随着相机的变化同步变化

## 获取相机 id

&emsp;相机的 id 组成是树结构, 根据情况有不同的层级数量(最多四层), 给了四个相关接口, 每个接口对应一个层级, 按照顺序先查询第一个接口, 从返回信息中获取保存相机信息的数组, 遍历节点, 根据每个元素的具体信息, 调用不同的接口, 传递参数, 获取下级孩子节点, 依次重复, 直到节点的类型表明是相机的叶子节点。

## 播放操作相机

* 播放: 播放相机视频的前端实现总共经历了三版, 第一个是直接调用 mpegts 实现播放(操作全部交给前端, 后台无法对视频画面进行操作); 第二个是使用 img 播放(延迟较大); 第三个是使用 websocket 传递数据, 调用 wasm 解析, 然后将解析的数据在前端使用 canvas 绘制出来, 后台控制延迟和操作图像(据说是一位飞升 p8 的大佬写的流程, 也是经历了两版)。

* 操作: 相机的操作就是控制球机的旋转的焦距的调节, 在当时遇到了一个问题, 比如说, 向右旋转这个指令, 发送之后就会一直向右旋转, 必须再发送一个停止的指令才行。如果视频播放的延迟较大的话, 就会感觉操作和视频画面很不协调, 这个最后一方面在技术上使用不同的播放方式来减少延迟, 另一方面在操作上, 在发出旋转等指令之后, 定时发送停止指令, 将一直旋转变为旋转一定角度。

## 绘制图形

&emsp;绘制图形就是在视频上再加一层 canvas 画布, 在上面绘制图形, 设置 canvas 的背景透明, 就会感觉好像在视频上绘制一样。具体的操作就是, 比如视频上有一个箱子, 我先使用 canvas 加载该场景的静态图片，然后在上面画个点加个文字标签进行说明, 然后上传后台。之后回到播放的视频控制相机变化, 箱子到了别的地方, canvas 上绘制的标签也会根据 websocket 传过来的数据随之重绘, 与视频画面保持一致，在视觉上让人觉得绘制的图像位置在视频内一样。

## 小结

&emsp;由于项目小, 前端都是我写的, 一个多月就完成了, 而且只是帮另外一个小组完成的小项目, 仅有的两个关键的技术点, 一个是视频播放 flv 流的播放我只是借用框架 mpegts.js, 并不了解原理。wasm 的也是直接用对方小组的文件, 最终实现即可, 充其量只是将其嵌入到项目中进行调用, 原理并不掌握; 另一个就是图像与视频保持一致, 这个主要属于后台的算法处理, 我只是负责传送和接受数据进行绘制。只能说除了 ui 操作和一些绘制的基本操作之外, 完全没有掌握核心科技, 妥妥的 API 调用工程师。

